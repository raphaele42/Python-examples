# Fitting regression models and using AIC to select the best model

# AIC is the Akaike information criterion used to select between several models. 
# It's designed to penalise models with lots of explanatory variables (or parameters)
# to aim for less complex models. In general, the model with the lowest AIC is preferable. 
# The AIC is given as part of the model summary with OLS. 

# The steps to run a forward selection AIC regression are: 
# 1. Run a regression model including only the intercept column and find the AIC.
# 2. Add in each explanatory variables individually, run a linear regression for 
#each one and determine how much they decrease the AIC
# 3. Determine which variable decreases AIC the most and include it in the model
# 4. Repeat step 2-3 with this new linear model and remaining explanatory variables
# 5. Repeat this process until none of the remaining explanatory variables reduce the AIC
# The explanatory variables that have been included up to the stopping point are considered the
# variables that produce a good fit without overcomplicating the model.

# Import packages
from pandas import Series, DataFrame
import pandas as pd
import numpy as np
import numpy.random as npr
import statsmodels.api as sm

# Importing the prostate dataset 
prostate = pd.read_csv('http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/prostate.data',index_col='Unnamed: 0',sep='\t')
# Remove categorical data
dataA = prostate.drop('train',axis=1)

# Write a function to create X (explanatory variables) and y (response variable) for a given DataFrame df. 
# The function inputs are the DataFrame df and the label of the response/endogenous variable res_col. The function
# returns two objects, X and y, where X and y are both standardised and the first column of X includes only 1s. 
def dataPrep(df,res_col):
    #Create X and y
    X = pd.DataFrame(df.drop(res_col,axis=1))
    y = pd.Series(df[res_col].values)
    # Standardise all values in X and y
    X = (X - X.mean()) / X.std() 
    y = (y - y.mean()) / y.std()
    #Add column of ones for intercept
    X.insert(0, 'intercept','1')
    return(X, y)

# Test the function
XA, yA = dataPrep(dataA,'lpsa') 

# Check XA and yA have the same number of rows and columns as dataA
len(XA)
len(yA)
len(dataA)

# Check the first column of XA is entirely ones
XA.intercept.unique()

# Check the mean of each variable in XA and yA (apart from the intercept column) is close to zero (~10^(-16))
XA.mean()
yA.mean()

# Check the std of each variable in XA and yA (apart from the intercept column) is 1
XA.std()
yA.std()

#Function that takes X and y as inputs and fits a linear regression model. The function should return the rsquared value 
# rounded to 4 decimals
def regFit(X,y):
    X = X.values
    mod = sm.OLS(y.astype(float), X.astype(float))  
    res = mod.fit() 
    return(round(res.rsquared, 4)) 

#Test the function
print(regFit(*dataPrep(dataA,'lpsa'))) # Should return 0.6634

# Function that performs the AIC algorithm for a given DataFrame X and Series y.
# The function returns the names of the columns used for the model that gives the lowest AIC.
def funAIC(X,y):
    modelDF = pd.DataFrame(X.iloc[:,[0]])
    Xmod = modelDF.values
    #fitting and testing the model with intercept only
    mod = sm.OLS(y.astype(float), Xmod.astype(float))  
    res = mod.fit() 
    oldAIC = res.aic
    #retrieve the number of parameters to go through
    n = len(X.columns)
    indToTest = list(range(1,n))
    #initialise the list of parameters to keep
    indToKeep = [0]
    for l in range(1, n):
        newAIC = []
        resAIC = []
        m = len(indToTest)
        for i in range(0, m):
            newRange = indToKeep.copy()
            newRange.append(indToTest[i])
            newDF = pd.DataFrame(X.iloc[:,newRange])
            Xmod = newDF.values
            mod = sm.OLS(y.astype(float), Xmod.astype(float))  
            res = mod.fit()
            improvAIC = res.aic - oldAIC 
            newAIC.append(improvAIC)
            resAIC.append(res.aic)
        if min(newAIC) < 0:
            bestInd = newAIC.index(min(newAIC))
            bestParam = indToTest[bestInd]
            oldAIC = min(resAIC)
            indToKeep.append(bestParam)
            indToTest.remove(bestParam)
    return(list(X.iloc[:,indToKeep].columns))

# Test the AIC function
print(funAIC(*dataPrep(dataA,'lpsa')))
# Should return ['intercept', 'lcavol', 'lweight', 'svi', 'lbph', 'age']
