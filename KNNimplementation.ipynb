{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNNimplementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmWE/4XSDh2YvTNU38FyyP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raphaele42/Python-examples/blob/master/KNNimplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZi2qfRBZCT7",
        "colab_type": "text"
      },
      "source": [
        "# Implementation of the k nearest neighbours algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZGREtWwVzlN",
        "colab_type": "text"
      },
      "source": [
        "k nearest neighbours algorithm applied on a sample of ~4000 observations the TunedIT data set, classified as either rock or not rock. There are 191 characteristics for each observations. The last variable RockOrNot denotes if the observation is either rock (1) or not rock (0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOc41CLvV3OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import packages\n",
        "from pandas import Series, DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import random\n",
        "from scipy.spatial.distance import pdist, squareform #for euclidean distance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKLa9CcJbEiP",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdYuFOO3WSZM",
        "colab_type": "text"
      },
      "source": [
        "Load in the data and look at the data. Note: tunedit_genres.csv is available in the current directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg5UGr0AWW0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "10b4196f-1a2f-4b09-cff7-2cfd35ba6739"
      },
      "source": [
        "data = pd.read_csv('tunedit_genres.csv')\n",
        "data.head()  #view 5 first observations\n",
        "data.describe()  #summary stats\n",
        "data.dtypes  #check variables data type"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PAR_TC                    float64\n",
              "PAR_SC                    float64\n",
              "PAR_SC_V                  float64\n",
              "PAR_ASE1                  float64\n",
              "PAR_ASE2                  float64\n",
              "                           ...   \n",
              "PAR_2RMS_TCD_10FR_MEAN    float64\n",
              "PAR_2RMS_TCD_10FR_VAR     float64\n",
              "PAR_3RMS_TCD_10FR_MEAN    float64\n",
              "PAR_3RMS_TCD_10FR_VAR     float64\n",
              "RockOrNot                   int64\n",
              "Length: 192, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOUZhKjLZM5b",
        "colab_type": "text"
      },
      "source": [
        "Determine percentage of the songs that are rock songs (to 1 d.p.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oylL-yo1ZbVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1398f004-3c86-41d3-a1fe-2a28a10b006f"
      },
      "source": [
        "# Frequency table for the RockOrNot variable\n",
        "table = data.RockOrNot.value_counts()\n",
        "# Computing the percentage of rock songs\n",
        "freqRock = round(table[1]/len(data)*100, 1)\n",
        "print(\"The percentage of rock songs is: \",freqRock)\n",
        "# Ans: 48.8%"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The percentage of rock songs is:  48.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozxkg9MYZphY",
        "colab_type": "text"
      },
      "source": [
        "'RockOrNot' is the classification variable. We need to separate it from the other variables. We will separate the data into a DataFrames X and a Series y, where:\n",
        " \n",
        "*   X contains a standardised version of all variables except for the classification variable ('RockOrNot')\n",
        "*   y contains only the classification variable\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n44mkvzaaUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Series for classification variable\n",
        "y = pd.Series(data['RockOrNot'].values)\n",
        "# Dataframe for predictive variables\n",
        "X = pd.DataFrame(data.drop('RockOrNot', axis=1).values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob_OTUMfaOlx",
        "colab_type": "text"
      },
      "source": [
        "We also need to standardise the variables in X, by subtracting the mean and dividing by the standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJeO1sFdanMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "19e817f6-28f6-4b68-da4d-cfb3481ba7f8"
      },
      "source": [
        "# Standardise all values in X\n",
        "X = (X - X.mean()) / X.std()\n",
        "# Check the standardisation was correct\n",
        "X.mean() #should be 0\n",
        "X.std()  #should be 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1.0\n",
              "1      1.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      1.0\n",
              "      ... \n",
              "186    1.0\n",
              "187    1.0\n",
              "188    1.0\n",
              "189    1.0\n",
              "190    1.0\n",
              "Length: 191, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwEbVi21a3qT",
        "colab_type": "text"
      },
      "source": [
        "# Splitting the data into training and data sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G7HTFFPa8-z",
        "colab_type": "text"
      },
      "source": [
        "The model will be fitted on the training set (75% of the original set). The remaining 25% is the test set, used to determine the performance of the model. \n",
        "\n",
        "X and y must be divided randomly into training and test sets. The split must match, for all the observations from X included in the training set, the corresponding observation in y must be included in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIgyToCDcdAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set a seed for the random split can be replicated\n",
        "random.seed(123)\n",
        "fullInd = list(X.index)   #full list of indices\n",
        "n = len(fullInd)\n",
        "trainProp = round(n*0.75)    #set number of items for training set\n",
        "#Select random items for training indices\n",
        "trainInd = random.sample(fullInd, trainProp)\n",
        "#Define test set indices as complement of training indices\n",
        "testInd = [x for i, x in enumerate(fullInd) if i not in trainInd]\n",
        "#Build training and test dfs based on indices lists\n",
        "trainX = X.iloc[trainInd]\n",
        "trainy = y[trainInd]\n",
        "testX = X.iloc[testInd]\n",
        "testy = y[testInd]\n",
        "# Test the split is correct by checking length of training and test sets\n",
        "# Expected split: 2999 / 1000\n",
        "len(testX)\n",
        "len(testy)\n",
        "len(trainX)\n",
        "len(trainy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQd5-qNBep2O",
        "colab_type": "text"
      },
      "source": [
        "# KNN function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7UVy6k2esC3",
        "colab_type": "text"
      },
      "source": [
        "The first function runs kNN (k Nearest Neighbours) on the data sets. How the algorithm works :\n",
        "1.\n",
        "\n",
        "1.   A value of k is chosed (usually odd)\n",
        "2.   For each observation, find its k closest neighbours\n",
        "3.   Take the majority vote (mean) of these neighbours\n",
        "4.   Classify the observation based on majority vote\n",
        "\n",
        "The distance between observations is based on the standard Euclidean distance.\n",
        "\n",
        "The function outputs a series y_star of predicted classification values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeyQUKIgf5fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kNN(X,y,k):\n",
        "    # Find the number of obsvervation\n",
        "    n = len(y)\n",
        "    # Set up return values\n",
        "    y_star = pd.Series(0, index=np.arange(n))\n",
        "    # Calculate the distance matrix for the observations in X\n",
        "    dist = pdist(X, metric='euclidean')\n",
        "    dist = squareform(dist)    \n",
        "    # Make all the diagonals very large so an observation can't choose itself as a closest neighbour\n",
        "    dist[dist == 0] = 300\n",
        "    # Loop through each observation to create predictions\n",
        "    kMean=0\n",
        "    for i in range(0, n): \n",
        "        # Find the y values of the k nearest neighbours\n",
        "        y_nearest = 0\n",
        "        allNeighbours = pd.Series(dist[i, ])\n",
        "        for j in range(1, k):\n",
        "            closestInd = allNeighbours.idxmin()\n",
        "            newClosest = y.iloc[closestInd]\n",
        "            y_nearest = y_nearest + newClosest\n",
        "            allNeighbours = allNeighbours.drop([closestInd])\n",
        "            #compute average of neighbours class\n",
        "            #round to nearest integer so result is 0 or 1\n",
        "            kMean = int(round(y_nearest / k))\n",
        "        # Allocate to y_star\n",
        "        y_star.iloc[i] = kMean\n",
        "    return y_star\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEu_lWOLgn_G",
        "colab_type": "text"
      },
      "source": [
        "# Select the best k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rq7gPpWglkN",
        "colab_type": "text"
      },
      "source": [
        "The best value of k is the one for which the misclassification rate is the smallest. This function kNN_select runs a kNN classification for a range of k values, and compute the misclassification rate for each.\n",
        "\n",
        "It returns a Series mis_class_rates, indexed by k, with the misclassification rates for each k value in k_vals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CZGWDdrhBcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kNN_select(X,y,k_vals):\n",
        "    m = len(k_vals)\n",
        "    #Initialise the series to store the misclassification rates\n",
        "    mis_class_rates = pd.Series(0, index=np.arange(m))\n",
        "    #Loop through all k values to apply KNN for each\n",
        "    for i in range(0, m): \n",
        "        kValue = k_vals[i]\n",
        "        predRes = kNN(X,y,kValue)\n",
        "        #Determine misclassification rate for this value of k\n",
        "        misClassRateNew = round(len(y[y.values != predRes.values]) / len(y), 2)\n",
        "        mis_class_rates.loc[i] = misClassRateNew\n",
        "    mis_class_rates.index = k_vals\n",
        "    return mis_class_rates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AuUpTfah9u7",
        "colab_type": "text"
      },
      "source": [
        "# Generalised Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQntDM1RiAK-",
        "colab_type": "text"
      },
      "source": [
        "This general function does:\n",
        "1.   Separate the data sets X and y into training and test sets where the number in each is specified by 'percent_train'.\n",
        "2.   Run the k nearest neighbours classification on the training data, for a set of k values, computing the mis-classification rate for each k. \n",
        "3.   Find the k that gives the lowest mis-classification rate for the training data, and hence, the classification with the best fit to the data.\n",
        "4.   Use the best k value to run the k nearest neighbours classification on the test data, and calculate the mis-classification rate for test data.\n",
        "\n",
        "The function returns the mis-classification rate for a k nearest neighbours classification on the test data, using the best k value for the training data. It uses the function defined above: KNN and KNN_select."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYO6pCfEjEds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kNN_classification(df,class_column,seed,percent_train,k_vals):\n",
        "    # df            - DataFrame to \n",
        "    # class_column  - column of df to be used as classification variable, should\n",
        "    #                 specified as a string  \n",
        "    # seed          - seed value for creating the training/test sets\n",
        "    # percent_train - percentage of data to be used as training data\n",
        "    # k_vals        - set of k values to be tests for best classification\n",
        "    \n",
        "    # Separate X and y\n",
        "    # Series for classification variable\n",
        "    y = pd.Series(df[class_column].values)\n",
        "    # Dataframe for predictive variables\n",
        "    X = pd.DataFrame(df.drop(class_column, axis=1).values)\n",
        "    # Standardise all values in X\n",
        "    X = (X - X.mean()) / X.std()\n",
        "    \n",
        "    # Divide into training and test\n",
        "    random.seed(seed)\n",
        "    fullInd = list(X.index)   #full list of indices\n",
        "    n = len(fullInd)\n",
        "    trainProp = round(n*percent_train)    #set number of items for training test\n",
        "    #Select random items for training indices\n",
        "    trainInd = random.sample(fullInd, trainProp)\n",
        "    #Define test set indices as complement of training indices\n",
        "    testInd = [x for i, x in enumerate(fullInd) if i not in trainInd]\n",
        "    #Build training and test dfs based on indices lists\n",
        "    trainX = X.iloc[trainInd]\n",
        "    trainy = y[trainInd]\n",
        "    testX = X.iloc[testInd]\n",
        "    testy = y[testInd]\n",
        "    \n",
        "    # Compute the mis-classification rates for each of the values in k_vals\n",
        "    MisclassRates = kNN_select(trainX,trainy,k_vals) \n",
        "    \n",
        "    # Find the best k value, by finding the minimum entry of mis_class_rates \n",
        "    bestK = MisclassRates.idxmin()\n",
        "    \n",
        "    # Run the classification on the test set to see how well the 'best fit'\n",
        "    # classifier does on new (test) data generated from the same source\n",
        "    predResTest = kNN(testX, testy, bestK)\n",
        "    \n",
        "    # Calculate the mis-classification rates for the test data\n",
        "    mis_class_test = round(len(testy[testy.values != predResTest.values]) / len(testy), 2)\n",
        "    print(\"The best value of k and related misclassification rate for test data are: \")\n",
        "    return [bestK,mis_class_test]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNUsSDCVlJvj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Run the generalised function on the music data set, using **RockOrNot** as the classifier, setting the seed at **123**, with **75**% of the data used for training and a set of values defined as k_vals.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8vr72DRjxmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ada05d35-ece4-4583-ec1c-42b42a20981f"
      },
      "source": [
        "k_vals = [1, 3, 5, 7, 9] \n",
        "kNN_classification(data,'RockOrNot',123,0.75,k_vals)   "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best value of k and related misclassification rate for test data are: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 0.06]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}